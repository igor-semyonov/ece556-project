\documentclass[12pt,english]{article}
\input{preamble.tex}

\title{
    A Spiking Neural Network Implemented in Rust
}
\author{Igor Semyonov}
\author{Kirby Steiner}
\affil{George Mason University}
% \date{}

\begin{document}

\maketitle

\begin{abstract}
    In this work, we explore writing a spiking neural network engine in the Rust programming language.
    We will consider possible methods for training including back propagation and neural generative coding.
    Our implementation is based in part on the work of Eshraghian, et al. \cite{snntorch} and the tutorials of the associated snntorch python package.
    We will profile the code, searching for and comparing optimization strategies.
\end{abstract}

The project repository is at \href{https://github.com/igor-semyonov/ece556-project}{https://github.com/igor-semyonov/ece556-project}.

\section{Related Literature}
Our project is situated at the intersection computer vision with spiking neural networks \cite{Hasan23} and generative neural coding \cite{OrorbiaKifer22} which in turn is influenced by the predictive processing \cite{Clark15, Bubic10, Kveraga07}, Bayesian brain \cite{Knill04, Deneve04, Kersten04}, and free energy \cite{Friston10} literatures.

\subsection{Generative Neural Coding}
Generative neural coding is a machine learning framework that seeks, ``to create a complete theory of inference and learning that emulates how the brain can learn complex functions from the environment." \cite{Ororbia23_a} This means that learning algorithms must face the same constraints that the brain does. An important implication of this is that the backprop algorithm cannot be used in this framework. While many frameworks approach issues with backprop from a training perspective (i.e. how to differentiate non-continuous spiking signals?), generative neural coding critiques backprop from a biological plausibility perspective.

There are six problems with the backprop from the persepective of biologically plausible machine learning \cite{Ororbia22, Ororbia23_a}.
\begin{enumerate}
    \item \textbf{The Global Feedback Pathway Problem:} Backpropagation of errors often results in a vanishing gradient. This is particularly common in training recurrent neural networks, which is  often resolved by unfolding the model backwards across time which violates biological plausibility.
    \item \textbf{The Weight Transport Problem:} Backprop's use of the same parameter matrix for the forward and backward pass implies that the same synaptic connections are used to pass information forward and to receive error messages. This contrasts with the predictive coding literature in neuroscience which shows that neurons have two sets of synapses: one excitatory synapse that passes state information up to the next layer and one inhibitory synapse that passes error information down to the previous layer \cite{WhittingtonBogacz19}.
    \item \textbf{The Problem of Locality and Locking:} Synaptic updating under backprop would imply that neurons wait for error information from a gloabl cost function and thus the activity of a neuron in a given layer is dependent on the behavior of neurons at all layers even if they are far away. This violoates the principle of locality in synaptic plasticity, which states that ``all information a synapse needs to update its state (e.g. its synaptic weight) is directly accessible in space and immediately accessible in time \cite{Khacef23}.
    \item \textbf{The Problem of Constraint and Sensitivity:}
    \item \textbf{The Problem of Short-Term Plasticity:}
    \item \textbf{The Inference Dependency Problem:}
\end{enumerate}


\subsection{Predictive Processing}
For a thorough review of predictive processing from theoretical and empirical perspectives we recommend the reader to see \cite{Millidge22}. 

\subsubsection{Theory}
Predictive processing theory in neuroscience argues that the brain learns representations of the world neither in a purely bottom-up nor a purely top-down manner\footnote{Interestingly, recent research in category theoretic foundations of deep learning noted that most current frameworks are either top-down or bottom-up\cite{}}. Rather, layers communicate to each other in a language of prediction and surprise. This leads to an important distinction in what spikes represent conceptually. Rather than spike rates representing the intensity of a sensory input, spike rates represent the amount of \textit{new} information that a sensory input brings with it. \cite{Clark15} offers an evolutionary rationale for why the brain would encode information in this way: most of the sensory input an organism receives is noisy and ambiguous. Without top-down predictions to compare with bottom-up inputs organisms would not be able to cope with the uncertainty. 



\subsubsection{Empirical Evidence}
Most of the empirical work in predictive processing began in the field of vision: how does sensory input in the retina propagate through the brain, allowing the brain to form meaningful representations of the world? The seminal work establishing the predictive processing theory was \cite{RaoBallard99}. Additional experimental support for predictive processing is cited in \cite{Millidge22, Bastos12}
\section{Implementation}

Currently, the implementation consists of two components: neuron and layer.
The neuron is a simple leaky integrate and fire (L.I.F.) neuron shown in listing \ref{lst-lif}.
The LIF has two associated functions: new and step.
New is the idiomatic way to write an initialization function.
While it is not necessary, as we can create a LIF struct directly, it allows us to ensure a certain way of creating the struct.
Also, if we make this framework available to others as a library, we could restrict the struct to be a private object, so users would have to use the $new$ function to create instances of LIF.

The $step$ function uses the current state of the LIF, along with input spikes, to return the next membrane potential value and any output spikes, if applicable.
Note, this function does not mutate the LIF in place, it produces the output necessary to update the LIF, but does not do so automatically.
In Rust mutability of variables is strictly controlled and must be managed with care.
I had to change this function to not mutate the LIF in order to allow for downstream use of the LIF struct.

\codefilelines{../src/main.rs}{
    Initial spiking neural network implementation
}{lst-lif}{5}{58}

Layer, shown in listing \ref{lst-layer} is the struct which holds a single layer of a network.
A whole network could also be encoded as a single layer. 
A layer contains one or more neurons, internal weights, memory for all neurons, and spikes in and out for all neurons.
It has three associated functions.
A $new$ function, which like for LIF, is the intended way to instantiate this struct.
The $step$ function performs steps for each neuron and records the spikes for the upcoming step as well as new memory, i.e., membrane potentials.
The $run$ function simply performs the necessary number of steps.
After this the $layer$ struct contains the results of the simulation.

The reason we chose to design it like this is to allow for multiple layers to interact with one another.
Each layer would run its own set of time steps in sequence.
Then it would pass the entire set of spikes to the next layer for downstream processing.

\codefilelines{../src/main.rs}{
    Initial spiking neural network implementation
}{lst-layer}{60}{170}

\section{Demonstration}

In listing \ref{lst-demo} we show the main function from the rust code which creates 3 neurons, an input spike, and a layer.
Then we run the layer and export the results to JSON.
This is made very easy because we derived the Serialize trait for both LIF and layer.
We then use a simple python script shown in listing \ref{lst-vis} to visualize the memory.
The output is shown in figure \ref{fig-mem}

\codefilelines{../src/main.rs}{
    Initial spiking neural network implementation
}{lst-demo}{172}{218}

\codefile{../visualize.py}{
    Visualization script
}{lst-vis}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{memory}
    \caption{Memory from 3-neuron-layer with a single input spike propagated through to the other neurons.}
    \label{fig-mem}
\end{figure}

\section{Next Steps}

Now that we have a somewhat functional model, we plan to tear it down and build it following the node-cable structure described by Orbia in \cite{NGC}.
Having built this much in rust already, it should be relatively straight forward to port the NGC architecture to rust, at least the basic components.

I am also considering implementing an evolutionary learning wrapper around the model we build.
This should be relatively doable, and the concurrency libraries in the rust ecosystem are amazing.
For other algorithms I have ported to rust, I have been amazed at how easy it is to perform parallel iteration.
One would think this would be easier in python: a much more high-level language, but with the Rayon crate, I was able to fully utilize all my CPU cores by simply changing one line of code.

%\section*{References}
% \nocite{hybrid-sparcity}
\bibliographystyle{siam}
\bibliography{refs}

%\layout*

\lstlistoflistings

\end{document}
